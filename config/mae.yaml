seed_everything: 123
trainer:
  gpus: 1
  strategy: ddp
  max_epochs: 100
  limit_val_batches: 0.0
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        filename: "{epoch}"
        save_last: True
        every_n_epochs: 10
        save_top_k: -1
        save_on_train_epoch_end: True
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        filename: latest
        every_n_epochs: 1
        save_on_train_epoch_end: True
    - class_path: pytorch_lightning.callbacks.lr_monitor.LearningRateMonitor
      init_args:
        logging_interval: step
model:
  class_path: mae.MAE
  init_args:
    image_size:
    - 224
    - 224
    patch_size: 16
    keep: 0.25
    enc_width: 768
    dec_width: 0.25
    enc_depth: 12
    dec_depth: 4
    lr: 0.00015
    # train_steps: ${training_steps:${data.init_args.num_samples},${data.init_args.batch_size},${trainer.gpus}}